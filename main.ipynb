{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(training,testing,comp,slvr,wht):\n",
    "    pca = PCA(n_components=comp,whiten=wht,svd_solver=slvr)\n",
    "\n",
    "    pca.fit(training)\n",
    "    inp_pca = pca.transform(training)\n",
    "    test_pca = pca.transform(testing)\n",
    "\n",
    "    return inp_pca, test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_lda(training, target, testing, slvr, shrink, n_com):\n",
    "    lda = LinearDiscriminantAnalysis(solver=slvr, shrinkage=shrink)\n",
    "    lda.fit(training, target)\n",
    "    transformed_data = lda.transform(training)\n",
    "    transformed_test = lda.transform(testing)\n",
    "    return transformed_data, transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(inp, num_clusters):\n",
    "    # optimise_clustering(inp)\n",
    "    kmeans = KMeans(n_clusters = num_clusters, n_init=10, random_state=0)\n",
    "    kmeans.fit(inp)\n",
    "    cluster_ids = kmeans.labels_\n",
    "    final = np.column_stack((inp, cluster_ids))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_clustering(inp, epsilon, min_s):\n",
    "    dbscan = DBSCAN(eps = epsilon, min_samples = min_s)\n",
    "    cluster_ids = dbscan.fit_predict(inp)\n",
    "    final = np.column_stack((inp, cluster_ids))\n",
    "    print(cluster_ids)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_clustering(inp):\n",
    "    wcss = []\n",
    "    for i in range(1,50):\n",
    "        kmeans = KMeans(n_clusters=i,n_init=10,random_state=42)\n",
    "        kmeans.fit(inp)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.plot(range(1, 50), wcss)\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(inp,labels,num,cont):\n",
    "    full = np.column_stack((inp,labels))\n",
    "    lof = LocalOutlierFactor(n_neighbors=num,n_jobs=-1)\n",
    "\n",
    "    # best = validation(full,lof)\n",
    "    # lof.set_params(n_neighbors = best)\n",
    "\n",
    "    preds = lof.fit_predict(inp)\n",
    "\n",
    "    out_array = np.empty((0,full.shape[1]))\n",
    "    for i in range(len(preds)):\n",
    "        if(preds[i]==1):\n",
    "            out_array = np.vstack((out_array, full[i]))\n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, Y_train, X_test, slvr, iterations, c, pen):\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train = scaler.fit_transform(X_train)\n",
    "    # X_test = scaler.transform(X_test)\n",
    "\n",
    "    logreg = LogisticRegression(multi_class='multinomial', solver=slvr, max_iter=iterations, C=c, penalty=pen)\n",
    "    bagging_lr = BaggingClassifier(estimator=logreg,n_estimators=10,max_samples=0.8,bootstrap=False,warm_start=False,n_jobs=-1,random_state=0)\n",
    "    bagging_lr.fit(X_train, Y_train)\n",
    "    y_pred = bagging_lr.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train, Y_train, X_test, depth, split, leaf, ftrs):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth,min_samples_split=split,min_samples_leaf=leaf,max_features=ftrs,random_state=21)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(inp,lof):\n",
    "    neighbors_range = range(5,50)\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    scores = np.empty(len(neighbors_range))\n",
    "\n",
    "    for i,n_neighbors in enumerate(neighbors_range):\n",
    "        lof.set_params(n_neighbors=n_neighbors)\n",
    "        cv_scores = cross_val_score(lof,inp[:,:-1],inp[:,-1],cv=kf,scoring='f1')\n",
    "        scores[i] = np.mean(cv_scores)\n",
    "    \n",
    "    best = neighbors_range[np.argmax(scores)]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "readtrain = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# mapping = {index: value for index,value in enumerate(readtrain['category'].unique())}\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# readtrain['category'] = le.fit_transform(readtrain['category'])\n",
    "\n",
    "labels = readtrain['category'].to_numpy()\n",
    "readtrain = readtrain.drop(['ID'],axis=1)\n",
    "data = readtrain.drop(['category'],axis=1).to_numpy()\n",
    "\n",
    "testdata = pd.read_csv(\"test.csv\")\n",
    "ids = testdata['ID']\n",
    "testdata = testdata.drop(['ID'],axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(data.shape[0]):\n",
    "#     for j in range(data.shape[1]):\n",
    "#         data[i][j] = data[i][j] + data[i][j]**2 + data[i][j]**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_scoring(estimator,X, Y=None):\n",
    "#     return -estimator.decision_function(X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lof = LocalOutlierFactor(n_jobs=-1)\n",
    "# hypers = {\n",
    "#     'n_neighbors':[5,10,15,20,24,30,32],\n",
    "#     'contamination':[0.01,0.05,0.08,0.1,None]\n",
    "# }\n",
    "# gs = GridSearchCV(lof,param_grid=hypers,cv=8,scoring=custom_scoring)\n",
    "# gs.fit(data,labels)\n",
    "\n",
    "# best_lof = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = best_lof.fit_predict(data)\n",
    "# data = data[preds!=-1]\n",
    "# labels = labels[preds!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = outlier_detection(data,labels,8,0.01)\n",
    "# for i in range(15,33):\n",
    "#     full = outlier_detection(data,labels,i)\n",
    "labels_out = full[:,-1]\n",
    "data_out = full[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 4096) (1211,)\n"
     ]
    }
   ],
   "source": [
    "print(data_out.shape,labels_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline([\n",
    "#     ('pca', PCA()),\n",
    "#     ('lda',LinearDiscriminantAnalysis()),\n",
    "#     ('logreg',LogisticRegression())\n",
    "# ])\n",
    "\n",
    "# params = {\n",
    "#     'pca__n_components':[0.9,0.99,0.999],\n",
    "#     'logreg__multi_class':['multinomial'],\n",
    "#     'logreg__solver':['lbfgs'],\n",
    "#     'logreg__max_iter':[2000],\n",
    "#     'logreg__C':[5,10,100],\n",
    "#     'logreg__penalty':['l1','l2']\n",
    "# }\n",
    "\n",
    "# grs = GridSearchCV(pipe,param_grid=params,cv=8)\n",
    "# grs.fit(data_out,labels_out)\n",
    "# best = grs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline([\n",
    "#     ('pca',PCA()),\n",
    "#     ('lda',LinearDiscriminantAnalysis()),\n",
    "#     ('dtc',DecisionTreeClassifier())\n",
    "# ])\n",
    "\n",
    "# params = {\n",
    "#     'pca__n_components':[0.99],\n",
    "#     'lda__solver':['eigen'],\n",
    "#     'lda__shrinkage':[None],\n",
    "#     'dtc__max_depth':[10,20,30,50,None],\n",
    "#     'dtc__min_samples_split':[2,5,10],\n",
    "#     'dtc__min_samples_leaf':[1,2,4],\n",
    "#     'dtc__max_features':['sqrt','log2',None]\n",
    "# }\n",
    "\n",
    "# grs = GridSearchCV(pipe,param_grid=params,cv=8)\n",
    "# grs.fit(data_out,labels_out)\n",
    "# best = grs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 355)\n"
     ]
    }
   ],
   "source": [
    "data_pca, testdata_pca = perform_pca(data_out,testdata,0.9897,'auto',False)\n",
    "print(data_pca.shape)\n",
    "data_lda, testdata_lda = perform_lda(data_pca, labels_out, testdata_pca, 'eigen', None, 19)\n",
    "\n",
    "# data_cl = kmeans_clustering(data_lda, 20)\n",
    "# testdata_cl = kmeans_clustering(testdata_lda, 20)\n",
    "\n",
    "# data = dbscan_clustering(data, 0.001, 120)\n",
    "# testdata = dbscan_clustering(testdata, 0.001, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_range = range(15,40)\n",
    "# accuracy_scores = []\n",
    "# for i in k_range:\n",
    "#     full = outlier_detection(data,labels,i)\n",
    "#     labels = full[:,-1]\n",
    "#     data = full[:,:-1]\n",
    "#     X_train, X_test, Y_train, Y_test = train_test_split(data,labels,test_size=0.25,random_state=100)\n",
    "#     Y_pred = classification(X_train,Y_train,X_test,1000)\n",
    "#     accuracy_scores.append(accuracy_score(Y_test,Y_pred))\n",
    "\n",
    "# print(k_range[np.argmax(accuracy_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(k_range,\"\\n\",accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(data_lda,labels_out,test_size=0.25,random_state=42)\n",
    "# Y_pred = logistic_regression(X_train,Y_train,X_test,1000,5,'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(data_lda,labels_out,test_size=0.25,random_state=42)\n",
    "# Y_pred = decision_tree(X_train,Y_train,X_test,None,8,1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = logistic_regression(data_lda,labels_out,testdata_lda,'lbfgs',1000,1,'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = decision_tree(data_lda,labels_out,testdata_lda,20,10,1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = le.inverse_transform(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'ID':ids,'category':output})\n",
    "output.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accuracy_score(Y_test,Y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
