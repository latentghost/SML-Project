{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1682,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(training,testing,comp,slvr,wht):\n",
    "    # pca = PCA(n_components=comp,svd_solver=slvr,whiten=wht)\n",
    "    pca = PCA(n_components=comp)\n",
    "\n",
    "    inp_pca = pca.fit_transform(training)\n",
    "    test_pca = pca.transform(testing)\n",
    "\n",
    "    return inp_pca, test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_lda(training, target, testing, slvr, shrink, n_com):\n",
    "    # lda = LinearDiscriminantAnalysis(n_components=n_com,solver=slvr,store_covariance=True)\n",
    "    lda = LinearDiscriminantAnalysis(n_components=n_com)\n",
    "    \n",
    "    transformed_data = lda.fit_transform(training,target)\n",
    "    transformed_test = lda.transform(testing)\n",
    "    return transformed_data, transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(inp, num_clusters):\n",
    "    # optimise_clustering(inp)\n",
    "    kmeans = KMeans(n_clusters = num_clusters, n_init=10, random_state=0)\n",
    "    kmeans.fit(inp)\n",
    "    cluster_ids = kmeans.labels_\n",
    "    final = np.column_stack((inp, cluster_ids))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_clustering(inp, epsilon, min_s):\n",
    "    dbscan = DBSCAN(eps = epsilon, min_samples = min_s)\n",
    "    cluster_ids = dbscan.fit_predict(inp)\n",
    "    final = np.column_stack((inp, cluster_ids))\n",
    "    print(cluster_ids)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1688,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_clustering(inp):\n",
    "    wcss = []\n",
    "    for i in range(1,50):\n",
    "        kmeans = KMeans(n_clusters=i,n_init=10,random_state=42)\n",
    "        kmeans.fit(inp)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.plot(range(1, 50), wcss)\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(inp,labels,num,cont,alg,met):\n",
    "    full = np.column_stack((inp,labels))\n",
    "    lof = LocalOutlierFactor(n_neighbors=num,algorithm=alg,metric=met)\n",
    "\n",
    "    # best = validation(full,lof)\n",
    "    # lof.set_params(n_neighbors = best)\n",
    "\n",
    "    preds = lof.fit_predict(inp)\n",
    "\n",
    "    return inp[preds==1], labels[preds==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, Y_train, X_test, slvr, iterations, c1, c2, c3, pen):\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train = scaler.fit_transform(X_train)\n",
    "    # X_test = scaler.transform(X_test)\n",
    "\n",
    "    logreg1 = LogisticRegression(multi_class='multinomial',max_iter=iterations,solver=slvr,C=c1,penalty=pen)\n",
    "    logreg2 = LogisticRegression(multi_class='multinomial',max_iter=iterations,solver=slvr,C=c2,penalty=pen)\n",
    "    logreg3 = LogisticRegression(multi_class='multinomial',max_iter=iterations,solver=slvr,C=c3,penalty=pen)\n",
    "\n",
    "    vf = VotingClassifier(estimators=[('lr1',logreg1),('lr2',logreg2),('lr3',logreg3)],voting='soft',weights=[2,1,1])\n",
    "    vf.fit(X_train,Y_train)\n",
    "\n",
    "    y_pred = vf.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train, Y_train, X_test, depth, split, leaf, ftrs):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth,min_samples_split=split,min_samples_leaf=leaf,max_features=ftrs,random_state=21)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(inp,lof):\n",
    "    neighbors_range = range(5,50)\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    scores = np.empty(len(neighbors_range))\n",
    "\n",
    "    for i,n_neighbors in enumerate(neighbors_range):\n",
    "        lof.set_params(n_neighbors=n_neighbors)\n",
    "        cv_scores = cross_val_score(lof,inp[:,:-1],inp[:,-1],cv=kf,scoring='f1')\n",
    "        scores[i] = np.mean(cv_scores)\n",
    "    \n",
    "    best = neighbors_range[np.argmax(scores)]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1693,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(inp,test,n1):\n",
    "    cov_matrix = np.corrcoef(inp,rowvar=False)\n",
    "    target_cov = np.abs(cov_matrix[:-1,-1])\n",
    "\n",
    "    cov_sort = np.argsort(target_cov)[::-1]\n",
    "    return inp[:, cov_sort[:n1]], test[:, cov_sort[:n1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "metadata": {},
   "outputs": [],
   "source": [
    "readtrain = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# mapping = {index: value for index,value in enumerate(readtrain['category'].unique())}\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# readtrain['category'] = le.fit_transform(readtrain['category'])\n",
    "\n",
    "labels = readtrain['category'].to_numpy()\n",
    "readtrain = readtrain.drop(['ID'],axis=1)\n",
    "data = readtrain.drop(['category'],axis=1).to_numpy()\n",
    "\n",
    "testdata = pd.read_csv(\"test.csv\")\n",
    "ids = testdata['ID']\n",
    "testdata = testdata.drop(['ID'],axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(data.shape[0]):\n",
    "#     for j in range(data.shape[1]):\n",
    "#         data[i][j] = data[i][j] + data[i][j]**2 + data[i][j]**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_scoring(estimator,X, Y=None):\n",
    "#     return -estimator.decision_function(X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lof = LocalOutlierFactor(n_jobs=-1)\n",
    "# hypers = {\n",
    "#     'n_neighbors':[5,10,15,20,24,30,32],\n",
    "#     'contamination':[0.01,0.05,0.08,0.1,None]\n",
    "# }\n",
    "# gs = GridSearchCV(lof,param_grid=hypers,cv=8,scoring=custom_scoring)\n",
    "# gs.fit(data,labels)\n",
    "\n",
    "# best_lof = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = best_lof.fit_predict(data)\n",
    "# data = data[preds!=-1]\n",
    "# labels = labels[preds!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1699,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out, labels_out = outlier_detection(data,labels,5,0.01,'ball_tree','euclidean')\n",
    "# for i in range(15,33):\n",
    "#     full = outlier_detection(data,labels,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1205, 4096) (1205,)\n"
     ]
    }
   ],
   "source": [
    "print(data_out.shape,labels_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "data_out, testdata = correlation_analysis(data_out,testdata,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1205, 263)\n"
     ]
    }
   ],
   "source": [
    "data_pca, testdata_pca = perform_pca(data_out,testdata,0.99,'auto',False)\n",
    "print(data_pca.shape)\n",
    "data_lda, testdata_lda = perform_lda(data_pca, labels_out, testdata_pca, 'eigen', None, 19)\n",
    "\n",
    "# data_cl = kmeans_clustering(data_lda, 20)\n",
    "# testdata_cl = kmeans_clustering(testdata_lda, 20)\n",
    "\n",
    "# data = dbscan_clustering(data, 0.001, 120)\n",
    "# testdata = dbscan_clustering(testdata, 0.001, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_range = range(15,40)\n",
    "# accuracy_scores = []\n",
    "# for i in k_range:\n",
    "#     full = outlier_detection(data,labels,i)\n",
    "#     labels = full[:,-1]\n",
    "#     data = full[:,:-1]\n",
    "#     X_train, X_test, Y_train, Y_test = train_test_split(data,labels,test_size=0.25,random_state=100)\n",
    "#     Y_pred = classification(X_train,Y_train,X_test,1000)\n",
    "#     accuracy_scores.append(accuracy_score(Y_test,Y_pred))\n",
    "\n",
    "# print(k_range[np.argmax(accuracy_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(k_range,\"\\n\",accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1706,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(data_lda,labels_out,test_size=0.25,random_state=42)\n",
    "# Y_pred = logistic_regression(X_train,Y_train,X_test,1000,5,'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(data_lda,labels_out,test_size=0.25,random_state=42)\n",
    "# Y_pred = decision_tree(X_train,Y_train,X_test,None,8,1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1708,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = logistic_regression(data_lda,labels_out,testdata_lda,'newton-cg',1000,1,1.25,1.5,'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = decision_tree(data_lda,labels_out,testdata_lda,20,10,1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = le.inverse_transform(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'ID':ids,'category':output})\n",
    "output.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accuracy_score(Y_test,Y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
